{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a network for object detection\n",
    "\n",
    "This puts everything together.\n",
    "Please note: I'm not training from scratch.\n",
    "YOLO is pretrained on imagenet, I simply don't have the resources for that.\n",
    "\n",
    "So I've used this code: https://github.com/allanzelener/YAD2K\n",
    "To export tiny yolo in keras format.\n",
    "\n",
    "From the exported model, I'm cutting off the \"regression head\".\n",
    "Only the convolutions up to the last maxpooling are taken, everything after that is new and trained with my setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,\"/home/lars/libraries/keras/\")\n",
    "import keras\n",
    "assert keras.__version__[0] == \"2\", \"we work on version 2 of keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization, SpatialDropout2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.callbacks import Callback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### allow dynamic memory allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=False #True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_model = load_model(\"models/yolo_1088_320_10_summarized.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extraction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = 10   # number of anchor boxes\n",
    "C = 5  # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pretrained weights shouldn't be updated any more\n",
    "# I'm only using them for feature extraction\n",
    "for layer in extraction_model.layers[:-21]:\n",
    "    print(layer.name)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_model = extraction_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters of the model\n",
    "\n",
    "These are training parameters.\n",
    "The input and output resolution are important for setting up the boxes as loss for training.\n",
    "The lambdas are factors to weigh the different loss components against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_tensor = detection_model.input\n",
    "\n",
    "in_x = int(input_tensor.shape[1])\n",
    "in_y = int(input_tensor.shape[2])\n",
    "\n",
    "output_tensor = detection_model.output\n",
    "\n",
    "out_x = int(output_tensor.shape[1])\n",
    "out_y = int(output_tensor.shape[2])\n",
    "\n",
    "lambda_coords = 10\n",
    "lambda_class = 2\n",
    "lambda_obj = 5\n",
    "lambda_noobj = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Set up the training data\n",
    "Follow the guide on the darknet side to set up VOC:\n",
    "https://pjreddie.com/darknet/yolo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare a config for the augmentations\n",
    "config={}\n",
    "config[\"max_hsv_scale\"] = [0, 0, 0]\n",
    "config[\"max_rotation\"] = 0\n",
    "config[\"max_shift\"] = 0\n",
    "config[\"zoom_range\"] = (0.9,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path= \"/home/lars/programming/kitti_labeler/out_split/train.txt\"\n",
    "test_path = \"/home/lars/programming/kitti_labeler/out_split/val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterator class to provide data to model.fit_generator\n",
    "from generator import Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "\n",
    "# generators for training data and test data\n",
    "train_gen = Augmenter(train_path, \n",
    "                      in_x, in_y, out_x, out_y,\n",
    "                      B, C, batch_size = batch_size)\n",
    "val_gen = Augmenter(test_path, \n",
    "                      in_x, in_y, out_x, out_y,\n",
    "                      B, C, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the generator\n",
    "batch = next(train_gen)\n",
    "imgs = batch[0]\n",
    "objects = batch[1]\n",
    "    \n",
    "plt.imshow(imgs[0, :,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "The loss function makes use of currying. Therefore this code is a little complicated.\n",
    "Keras expects a loss in this format loss(y_true, y_pred).\n",
    "\n",
    "But the loss_func in loss.py needs to know additional parameters such as the network size.\n",
    "I'm feeding that data by currying the loss_func and providing the additional parameters now.\n",
    "The result is a function with two remaining parameters and a signature as expected by keras.\n",
    "\n",
    "This currying can go very wrong, if you mix up the order of the parameters.\n",
    "If the loss function is called, it prints the parameters it has been given.\n",
    "Be sure to check this.\n",
    "Look at model.compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# anchor boxes are taken from the tiny yolo voc config\n",
    "anchors = np.zeros((B, 2))\n",
    "anchors[:] =np.array([0.18, 0.44, 0.23, 1.35, 0.33, 3.58, 0.43, 0.56, 0.49, 1.87, 0.66, 5.55, 0.99, 2.83, 1.01, 0.83, 1.61,6.34, 3.00,2.70]).reshape((B, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the anchors are given as width, height\n",
    "# this doesn't work with numpy's layout\n",
    "# we have to switch the x and y dimensions\n",
    "\n",
    "temp = anchors[:,0].copy()\n",
    "anchors[:,0]=anchors[:,1]\n",
    "anchors[:,1]= temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from loss_function import loss_func\n",
    "\n",
    "\n",
    "meta_data = [anchors, out_x, out_y, B, C, lambda_class, lambda_coords, lambda_obj, lambda_noobj]\n",
    "loss = loss_func(*meta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training the model\n",
    "Compile with the custom loss, set up a few callbacks and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "# check this: are the parameters correct ?\n",
    "#detection_model.compile(Adam(lr=1e-7), loss)\n",
    "\n",
    "detection_model.compile(SGD(lr=1e-7, momentum=0.1, decay = 1e-7), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# taken from the keras source\n",
    "# if the learning rate is too fast, NaNs can occur, stop the training in this case\n",
    "class TerminateOnNaN(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.seen = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.seen += 1\n",
    "        \n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        \n",
    "        if loss is not None:\n",
    "            if np.isnan(loss) or np.isinf(loss):\n",
    "                print('Batch %d: Invalid loss, terminating training' % (batch))\n",
    "                print(\"logs: \", logs)\n",
    "                \n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_terminator = TerminateOnNaN()\n",
    "\n",
    "# train in small steps and append histories\n",
    "# if training is interrupted, the history array still contains usable data\n",
    "import time\n",
    "histories = []\n",
    "times = []\n",
    "for i in range(20):\n",
    "    history=detection_model.fit_generator(train_gen, 6400//batch_size, \n",
    "                                          epochs=5, \n",
    "                                          callbacks=[nan_terminator],\n",
    "                                          validation_data = val_gen,\n",
    "                                          validation_steps = 1600//batch_size,\n",
    "                                          #use_multiprocessing=False)\n",
    "                                          workers =4,\n",
    "                                          max_queue_size=24)\n",
    "    histories.append(history)\n",
    "    times.append(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the test / val loss\n",
    "As you can see, the model reaches about 1000 for validation loss.\n",
    "Then it overfits.\n",
    "\n",
    "This number can't be interpreted correctly. It depends on the size of the network and the batch.\n",
    "A solution would be to take the mean in the loss instead of summing all components.\n",
    "But that would mess with the learning rate.\n",
    "\n",
    "I'm evaluating the pretrained model against the validation generator.\n",
    "Surprisingly, the new model reaches better scores.\n",
    "A possible explanation: The original yolo doesn't use rotations as augmentations. The validation generator uses rotations.\n",
    "Or the number of samples from the validation set was simply too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for item in histories:\n",
    "    losses.extend(item.history[\"loss\"])\n",
    "    val_losses.extend(item.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.legend([\"train\", \"val\"])\n",
    "plt.title(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two important helper functions to work with the data\n",
    "with get_probabilities you can extract the predicted classes, objectness and the combined probability from the output of the network\n",
    "\n",
    "the extract_from_blob helps with the blob of data fed to the keras loss.\n",
    "This blob is hard to read, so the function slices the individual parts out of it and converts them to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del extract_from_blob\n",
    "#del get_probabilities\n",
    "from utils.prediction import extract_from_blob, get_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = val_gen\n",
    "# get some sample data\n",
    "batch = next(test_gen)\n",
    "img = batch[0].copy()\n",
    "\n",
    "plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the data to the model\n",
    "predictions = detection_model.predict(batch[0])\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing given objectness with confidence of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract the given objectness for this image\n",
    "loss_dict = extract_from_blob(batch[1], out_x, out_y, B, C)\n",
    "\n",
    "# read the given objectness out of the loss dictionary\n",
    "f_objectness = loss_dict[\"f_objectness\"].reshape((-1,out_x, out_y, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data out of the predictions\n",
    "classes, objectness, probs = get_probabilities(predictions[0], out_x, out_y, B, C)\n",
    "\n",
    "# probs is along the B dimension\n",
    "# for every cell in the output activation map, get the best bounding box score\n",
    "max_probs = probs.max(axis=-1)\n",
    "\n",
    "threshold = 0.3\n",
    "thresholded = max_probs > threshold\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(10,10))\n",
    "\n",
    "\n",
    "axes[0].imshow(f_objectness[0,:,:,0])\n",
    "axes[0].set_title(\"given objectness\")\n",
    "\n",
    "axes[1].imshow(max_probs)\n",
    "axes[1].set_title(\"confidence\")\n",
    "\n",
    "axes[2].imshow(thresholded)\n",
    "axes[2].set_title(\"thresholded\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_probs.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the predicted bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.activations import np_sigmoid, softmax\n",
    "\n",
    "from nms import get_detections, apply_nms, idx_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = get_detections(predictions[0], threshold, anchors, out_x, out_y, in_x, in_y, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of detections: \", len(detections))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Max Suppression\n",
    "Sometimes yolo will predict the same object in more than one cell.\n",
    "This happens mostly for very big objects where the center of the object is not clear.\n",
    "\n",
    "We need non-max suppression to remove overlapping bounding boxes.\n",
    "\n",
    "We apply the non-max suppression to each label separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# taken from the yolo repository\n",
    "names = [\"tree trunk\",\n",
    "\"traffic light\",\n",
    "\"traffic sign\",\n",
    "\"lantern\",\n",
    "\"pole\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nms = apply_nms(detections, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nms = idx_to_name(nms, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"we found the following boxes after non-max suppression\")\n",
    "print(nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the output\n",
    "I'm using opencv to draw rectangles around all detections\n",
    "and to write the name in text onto the image.\n",
    "\n",
    "The image has a very low resolution.\n",
    "For the output it is upscaled.\n",
    "The main reason for this is to allow high-res text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = batch[0][0]\n",
    "output_img = img.copy()\n",
    "dim_x, dim_y = output_img.shape[:2]\n",
    "factor = 5\n",
    "output_img = cv2.resize(output_img, (dim_y*factor, dim_x*factor))\n",
    "\n",
    "for label in nms:\n",
    "    boxes = nms[label]\n",
    "    for box in boxes:\n",
    "        min_x, min_y, max_x, max_y = box\n",
    "        min_x *= factor\n",
    "        min_y *= factor\n",
    "        max_x *= factor\n",
    "        max_y *= factor\n",
    "        \n",
    "    \n",
    "        cv2.rectangle(output_img,(min_y, min_x),(max_y, max_x),(0,1,0),10)\n",
    "        #cv2.rectangle(output_img,(min_y-100, min_x-100),(min_y + 100, min_x+100),(0,1,0),-1)\n",
    "        cv2.putText(output_img, label, (min_y, min_x), cv2.FONT_HERSHEY_SIMPLEX, fontScale=3.5, color=(1, 1, 1), thickness=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(output_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
